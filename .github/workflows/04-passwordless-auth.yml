name: 03) Enforce Passwordless Auth (Managers)

on:
  workflow_dispatch: {}

permissions:
  contents: read

concurrency:
  group: passwordless-${{ github.ref }}
  cancel-in-progress: true

jobs:
  passwordless:
    if: ${{ github.event_name == 'workflow_dispatch' }}
    runs-on: [self-hosted, linux, ronin, k8s, control-plane]
    timeout-minutes: 45
    env:
      NS: wazuh
      KUBECONFIG: ${{ github.workspace }}/kubeconfig.yaml
      RAW_KCFG: ${{ secrets.KUBECONFIG }}
      KCFG_B64: ${{ secrets.KUBECONFIG_B64 }}
      KCFG_B64_ALT: ${{ secrets.KUBE_CONFIG_B64 }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Mask secrets (if present)
        shell: bash
        run: |
          for v in RAW_KCFG KCFG_B64 KCFG_B64_ALT; do
            val="${!v:-}"
            if [ -n "$val" ]; then
              echo "::add-mask::$val"
            fi
          done

      - name: Ensure CLIs (kubectl + yq) no sudo
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$HOME/.local/bin"
          if ! command -v kubectl >/dev/null 2>&1; then
            curl -fsSL -o "$HOME/.local/bin/kubectl" "https://dl.k8s.io/release/$(curl -fsSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            chmod +x "$HOME/.local/bin/kubectl"
          fi
          if ! command -v yq >/dev/null 2>&1; then
            curl -fsSL -o "$HOME/.local/bin/yq" "https://github.com/mikefarah/yq/releases/download/v4.44.3/yq_linux_amd64"
            chmod +x "$HOME/.local/bin/yq"
          fi
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Write kubeconfig from secrets
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${RAW_KCFG:-}" ]; then
            printf '%s' "$RAW_KCFG" > "$KUBECONFIG"
          elif [ -n "${KCFG_B64:-}" ]; then
            printf '%s' "$KCFG_B64" | base64 -d > "$KUBECONFIG"
          elif [ -n "${KCFG_B64_ALT:-}" ]; then
            printf '%s' "$KCFG_B64_ALT" | base64 -d > "$KUBECONFIG"
          else
            echo "::error::No kubeconfig secret found. Provide one of: KUBECONFIG (raw), KUBECONFIG_B64 (b64), or KUBE_CONFIG_B64 (b64)."
            exit 1
          fi
          chmod 600 "$KUBECONFIG"

      # ---- SANITY FIRST ----
      - name: Sanity check cluster connectivity
        shell: bash
        env:
          KUBECONFIG: ${{ env.KUBECONFIG }}
        run: |
          set -euo pipefail
          echo "== kubectl client version =="; kubectl version --client
          echo "== Cluster info =="; kubectl cluster-info
          echo "== Nodes =="; kubectl get nodes -o wide
          echo "== Managers =="; kubectl -n "$NS" get pods -l app=wazuh-manager -o wide

      # ---- (OPTIONAL) Patch ConfigMaps if any hold ossec.conf ----
      - name: Patch manager ossec.conf in ConfigMaps to passwordless (1515)  # optional; may warn if none
        shell: bash
        env:
          KUBECONFIG: ${{ env.KUBECONFIG }}
        run: |
          set -euo pipefail
          CM_NAMES="$(
            { kubectl -n "$NS" get sts -l app=wazuh-manager \
                -o jsonpath='{range .items[*].spec.template.spec.volumes[*]}{.configMap.name}{"\n"}{end}';
              kubectl -n "$NS" get pods -l app=wazuh-manager \
                -o jsonpath='{range .items[*].spec.volumes[*]}{.configMap.name}{"\n"}{end}';
            } 2>/dev/null | sort -u | sed '/^$/d' || true
          )"
          if [ -z "$CM_NAMES" ]; then
            echo "::warning::No manager ConfigMaps found that hold ossec.conf (skipping CM patch)"
          else
            for CM in $CM_NAMES; do
              echo ">> Processing ConfigMap: $CM"
              kubectl -n "$NS" get cm "$CM" -o yaml > "/tmp/${CM}.yaml"
              OSSEC="$(yq -r '.data."ossec.conf"' "/tmp/${CM}.yaml" || true)"
              if [ -z "$OSSEC" ] || [ "$OSSEC" = "null" ]; then
                echo "::warning::${CM} has no data.ossec.conf; skipping"
                continue
              fi
              yq -i '
                .data."ossec.conf" =
                  (.data."ossec.conf"
                    | sub("(?s)(<auth>)(.*?)(</auth>)";
                          capture("(?s)(?<open><auth>)(?<body>.*?)(?<close></auth>)") as $m
                          | ($m.body
                              | sub("<use_password>[^<]+</use_password>"; "<use_password>no</use_password>")
                              | sub("<port>[^<]+</port>"; "<port>1515</port>")
                              | sub("(?s)[[:space:]]*<password>[^<]*</password>[[:space:]]*"; "")
                            ) as $nb
                          | "\($m.open)\($nb)\($m.close)"
                    )
                  )
              ' "/tmp/${CM}.yaml"
              kubectl -n "$NS" apply -f "/tmp/${CM}.yaml"
            done
          fi

      # ---- ENFORCE INSIDE RUNNING PODS (no pod restart) ----
      - name: Force passwordless in running pods, purge authd.pass, reload wazuh-control
        shell: bash
        env:
          KUBECONFIG: ${{ env.KUBECONFIG }}
        run: |
          set -euo pipefail
          PODS="$(kubectl -n "$NS" get pods -l app=wazuh-manager -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}')"
          if [ -z "$PODS" ]; then
            echo "::error::No wazuh-manager pods found"; exit 1
          fi
          for P in $PODS; do
            echo "Patching $P ..."
            kubectl -n "$NS" exec "$P" -c wazuh-manager -- sh -lc '
              set -e
              f=/var/ossec/etc/ossec.conf
              cp "$f" "${f}.bak.$(date +%s)" || true
              # Set port 1515 and use_password no within the <auth> block
              awk -v RS= -v ORS="" '"'"'
                /<auth>/,/<\/auth>/ {
                  gsub(/<use_password>[^<]+<\/use_password>/, "<use_password>no</use_password>")
                  gsub(/<port>[^<]+<\/port>/, "<port>1515</port>")
                }
                { print }
              '"'"' "$f" > "$f.tmp" && mv "$f.tmp" "$f"
              # Remove any <password>...</password> lines inside <auth>
              awk '"'"'BEGIN{inauth=0} /<auth>/{inauth=1} inauth && /<password>.*<\/password>/{next} /<\/auth>/{inauth=0} {print}'"'"' "$f" > "$f.tmp" && mv "$f.tmp" "$f"
              # Ensure no legacy password file remains
              rm -f /var/ossec/etc/authd.pass || true
              echo "----- <auth> after patch (pod $(hostname)) -----"
              awk '"'"'/<auth>/{p=1} p; /<\/auth>/{exit}'"'"' "$f"
              # Reload manager in-place (no pod restart)
              /var/ossec/bin/wazuh-control restart
            '
          done

      # ---- VERIFY (robust awk; no angle-bracket quoting issues) ----
      - name: Verify passwordless (hard fail if misconfigured)
        shell: bash
        env:
          KUBECONFIG: ${{ env.KUBECONFIG }}
        run: |
          set -euo pipefail
          FAIL=0
          PODS="$(kubectl -n "$NS" get pods -l app=wazuh-manager -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}' || true)"
          if [ -z "$PODS" ]; then
            echo "::error::No wazuh-manager pods found"
            exit 1
          fi
          for P in $PODS; do
            echo "Checking $P ..."
            # Print the <auth> block for visibility
            kubectl -n "$NS" exec "$P" -c wazuh-manager -- sh -lc \
              "awk '/<auth>/{p=1} p; /<\\/auth>/{exit}' /var/ossec/etc/ossec.conf" || true

            USEPW="$(kubectl -n "$NS" exec "$P" -c wazuh-manager -- sh -lc \
              "awk -F\"[<>]\" '/<auth>/{p=1} p&&/use_password/{print \$3; exit}' /var/ossec/etc/ossec.conf" || true)"
            PORT="$(kubectl -n "$NS" exec "$P" -c wazuh-manager -- sh -lc \
              "awk -F\"[<>]\" '/<auth>/{p=1} p&&/port/{print \$3; exit}' /var/ossec/etc/ossec.conf" || true)"
            AUTHD_PASS_PRESENT="$(kubectl -n "$NS" exec "$P" -c wazuh-manager -- sh -lc \
              '[ -f /var/ossec/etc/authd.pass ] && echo present || echo absent')"

            echo "  use_password: ${USEPW:-<none>}"
            echo "  port:        ${PORT:-<none>}"
            echo "  authd.pass:  $AUTHD_PASS_PRESENT"

            if [ "${USEPW:-}" != "no" ]; then
              echo "::error file=/var/ossec/etc/ossec.conf,title=Password still enabled::$P has <use_password>${USEPW:-missing}</use_password>"
              FAIL=1
            fi
            if [ "${PORT:-}" != "1515" ]; then
              echo "::error file=/var/ossec/etc/ossec.conf,title=Wrong authd port::$P has <port>${PORT:-missing}</port>"
              FAIL=1
            fi
            if [ "$AUTHD_PASS_PRESENT" = "present" ]; then
              echo "::error file=/var/ossec/etc/authd.pass,title=Password file present::$P has /var/ossec/etc/authd.pass present (should be absent)"
              FAIL=1
            fi
          done
          if [ "$FAIL" -ne 0 ]; then
            echo "::error::One or more wazuh-manager pods are not passwordless. See errors above."
            exit 1
          fi
          echo "All wazuh-manager pods verified passwordless on port 1515."

      # ---- Optional: bounce agents so they enroll immediately ----
      - name: Bounce agent pods to retry enrollment
        shell: bash
        env:
          KUBECONFIG: ${{ env.KUBECONFIG }}
        run: |
          set -euo pipefail
          if kubectl -n "$NS" get ds wazuh-agent >/dev/null 2>&1; then
            echo "Deleting existing agent pods so they retry against passwordless manager..."
            kubectl -n "$NS" delete pods -l app=wazuh-agent --ignore-not-found=true
            sleep 5
            kubectl -n "$NS" get pods -l app=wazuh-agent -o wide
          else
            echo "No wazuh-agent DaemonSet found â€” skipping bounce."
          fi

      - name: Final manager service check (non-destructive)
        shell: bash
        env:
          KUBECONFIG: ${{ env.KUBECONFIG }}
        run: |
          set -euo pipefail
          echo "Services in $NS:"
          kubectl -n "$NS" get svc -o wide || true
