name: 01) Wazuh â€” Storage + Core (single-node friendly)

on:
  workflow_dispatch:
    inputs:
      overlay:
        description: "Overlay to deploy (single or production) [ignored if repo uses single root kustomization]"
        required: true
        default: "single"
      wazuh_tag:
        description: "wazuh-kubernetes repo tag (e.g., v4.12.0)"
        required: true
        default: "v4.12.0"
      enable_port_forward:
        description: "Start port-forward to dashboard (true/false)"
        required: true
        default: "true"
      local_forward_port:
        description: "Local port for port-forward"
        required: true
        default: "8444"

jobs:
  storage_core:
    runs-on: [self-hosted, linux, ronin, k8s, control-plane]
    timeout-minutes: 120

    env:
      NS: wazuh
      KUBECONFIG_PATH: ${{ github.workspace }}/kubeconfig.yaml
      KUBECONFIG:      ${{ github.workspace }}/kubeconfig.yaml
      WAZUH_K8S_TAG:   ${{ inputs.wazuh_tag }}
      OVERLAY_CHOICE:  ${{ inputs.overlay }}
      RAW_KCFG:        ${{ secrets.KUBECONFIG }}
      KCFG_B64_A:      ${{ secrets.KUBE_CONFIG_B64 }}
      KCFG_B64_B:      ${{ secrets.KUBECONFIG_B64 }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Mask secrets (whichever exist)
        shell: bash
        run: |
          set -euo pipefail
          for v in RAW_KCFG KCFG_B64_A KCFG_B64_B; do
            if [ -n "${!v:-}" ]; then echo "::add-mask::${!v}"; fi
          done

      - name: Install CLIs (no sudo) and persist PATH
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$HOME/bin"
          echo "$HOME/bin" >> "$GITHUB_PATH"   # <-- make tools available to ALL later steps
          export PATH="$HOME/bin:$PATH"

          # kubectl
          if ! command -v kubectl >/dev/null 2>&1; then
            KVER="$(curl -sS https://dl.k8s.io/release/stable.txt)"
            curl -sSL "https://dl.k8s.io/release/${KVER}/bin/linux/amd64/kubectl" -o "$HOME/bin/kubectl"
            chmod +x "$HOME/bin/kubectl"
          fi

          # yq
          if ! command -v yq >/dev/null 2>&1; then
            curl -sSL -o "$HOME/bin/yq" https://github.com/mikefarah/yq/releases/download/v4.44.3/yq_linux_amd64
            chmod +x "$HOME/bin/yq"
          fi

          # jq
          if ! command -v jq >/dev/null 2>&1; then
            curl -sSL -o "$HOME/bin/jq" https://github.com/jqlang/jq/releases/download/jq-1.7.1/jq-linux-amd64
            chmod +x "$HOME/bin/jq"
          fi

      - name: Write kubeconfig (supports raw or base64, both names)
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${RAW_KCFG:-}" ]; then
            printf '%s' "$RAW_KCFG" > "$KUBECONFIG_PATH"
          elif [ -n "${KCFG_B64_A:-}" ]; then
            printf '%s' "$KCFG_B64_A" | base64 -d > "$KUBECONFIG_PATH"
          elif [ -n "${KCFG_B64_B:-}" ]; then
            printf '%s' "$KCFG_B64_B" | base64 -d > "$KUBECONFIG_PATH"
          else
            echo "::error::No kubeconfig secret found (add KUBECONFIG or KUBE_CONFIG_B64 or KUBECONFIG_B64)"; exit 1
          fi
          chmod 600 "$KUBECONFIG_PATH"
          kubectl cluster-info
          kubectl get nodes -o wide

      - name: Ensure namespace exists
        shell: bash
        run: kubectl create namespace "$NS" --dry-run=client -o yaml | kubectl apply -f -

      - name: Ensure vm.max_map_count via DaemonSet
        shell: bash
        run: |
          cat > /tmp/wazuh-sysctl-ds.yaml <<'EOF'
          apiVersion: apps/v1
          kind: DaemonSet
          metadata: { name: wazuh-sysctl, namespace: kube-system, labels: { app: wazuh-sysctl } }
          spec:
            selector: { matchLabels: { app: wazuh-sysctl } }
            template:
              metadata: { labels: { app: wazuh-sysctl } }
              spec:
                hostPID: true
                tolerations: [ { operator: "Exists" } ]
                containers:
                  - name: sysctl
                    image: busybox:1.36
                    securityContext: { privileged: true }
                    command: ["/bin/sh","-c"]
                    args:
                      - |
                        set -e
                        echo 262144 > /host-proc/sys/vm/max_map_count
                        mkdir -p /host-etc/sysctl.d
                        echo "vm.max_map_count=262144" > /host-etc/sysctl.d/99-wazuh.conf
                        echo "node: $(hostname) vm.max_map_count=$(cat /host-proc/sys/vm/max_map_count)"
                        sleep 3600
                    volumeMounts:
                      - { name: host-proc, mountPath: /host-proc }
                      - { name: host-etc,  mountPath: /host-etc  }
                volumes:
                  - { name: host-proc, hostPath: { path: /proc, type: Directory } }
                  - { name: host-etc,  hostPath: { path: /etc,  type: Directory } }
          EOF
          kubectl apply -f /tmp/wazuh-sysctl-ds.yaml

      - name: Prepare StorageClass alias 'wazuh-storage'
        shell: bash
        run: |
          set -euo pipefail
          # Try default dynamic SC; if missing, fall back to local-path (assumes it's present on your node)
          TARGET_SC="$(kubectl get sc -o json | yq -r '.items[] | select(.metadata.annotations."storageclass.kubernetes.io/is-default-class"=="true") | .metadata.name' | head -n1 || true)"
          if [ -z "${TARGET_SC:-}" ]; then
            echo "::warning::No default dynamic StorageClass found; using 'local-path' (ensure local-path-provisioner is installed)"
            TARGET_SC="local-path"
          fi
          PROV="$(kubectl get sc "$TARGET_SC" -o jsonpath='{.provisioner}')"
          cat <<EOF | kubectl apply -f -
          apiVersion: storage.k8s.io/v1
          kind: StorageClass
          metadata: { name: wazuh-storage }
          provisioner: ${PROV}
          reclaimPolicy: Delete
          volumeBindingMode: WaitForFirstConsumer
          allowVolumeExpansion: true
          EOF
          kubectl get sc -o wide

      - name: Fetch wazuh-kubernetes repo
        shell: bash
        run: git clone --depth 1 --branch "$WAZUH_K8S_TAG" https://github.com/wazuh/wazuh-kubernetes.git

      - name: Generate self-signed certs (indexer/dashboard)
        shell: bash
        run: |
          set -e
          CERTROOT="${{ github.workspace }}/wazuh-kubernetes/wazuh/certs"
          IC="${CERTROOT}/indexer_cluster"
          DH="${CERTROOT}/dashboard_http"
          mkdir -p "$IC" "$DH"

          # Root CA
          openssl genrsa -out "$IC/root-ca-key.pem" 4096
          openssl req -x509 -new -key "$IC/root-ca-key.pem" -sha256 -days 3650 -out "$IC/root-ca.pem" -subj "/CN=Wazuh Root CA"

          # Quick leaf certs
          for n in admin node dashboard filebeat; do
            openssl req -x509 -nodes -days 825 -newkey rsa:2048 \
              -keyout "$IC/$n-key.pem" -out "$IC/$n.pem" -subj "/CN=$n"
          done

          # Dashboard TLS
          openssl req -x509 -nodes -days 825 -newkey rsa:2048 \
            -keyout "$DH/key.pem" -out "$DH/cert.pem" -subj "/CN=dashboard"

      - name: Build overlay (yaml) + single-node tweaks
        shell: bash
        run: |
          set -e
          kubectl kustomize "wazuh-kubernetes/wazuh" > /tmp/wazuh-all.yaml

          # Drop any StorageClass objects from upstream (we've already created our alias)
          yq -i 'del(.[] | select(.kind=="StorageClass"))' /tmp/wazuh-all.yaml

          # Single-node: scale Indexer to 1 replica and bump initial PVC sizes
          yq -i '
            # replicas: 1 for indexer
            (.[] | select(.kind=="StatefulSet" and .metadata.name=="wazuh-indexer").spec.replicas) = 1 |

            # Indexer PVC -> 60Gi
            (.[] | select(.kind=="StatefulSet" and .metadata.name=="wazuh-indexer")
              .spec.volumeClaimTemplates[]?).spec.resources.requests.storage = "60Gi" |

            # Manager master PVC -> 20Gi
            (.[] | select(.kind=="StatefulSet" and .metadata.name=="wazuh-manager-master")
              .spec.volumeClaimTemplates[]?).spec.resources.requests.storage = "20Gi"
          ' /tmp/wazuh-all.yaml

      - name: Apply non-StatefulSet resources
        shell: bash
        run: |
          yq -o=y e 'select(.kind != "StatefulSet")' /tmp/wazuh-all.yaml > /tmp/non-sts.yaml
          if [ -s /tmp/non-sts.yaml ]; then kubectl -n "$NS" apply -f /tmp/non-sts.yaml; fi

      - name: Apply StatefulSets
        shell: bash
        run: |
          yq -o=y e 'select(.kind == "StatefulSet")' /tmp/wazuh-all.yaml > /tmp/sts.yaml
          kubectl -n "$NS" apply -f /tmp/sts.yaml

      - name: Wait for core
        shell: bash
        run: |
          for sel in "app=wazuh-indexer" "app=wazuh-manager" "app=wazuh-dashboard"; do
            echo "Waiting for: $sel"
            kubectl -n "$NS" wait --for=condition=Ready pod -l "$sel" --timeout=1200s || true
            kubectl -n "$NS" get pods -l "$sel" -o wide
          done

      - name: Discover dashboard port
        id: dash
        shell: bash
        run: |
          set -euo pipefail
          P="$(kubectl -n "$NS" get svc -l app=wazuh-dashboard -o jsonpath='{.items[0].spec.ports[0].port}' 2>/dev/null || true)"
          if [ -z "${P:-}" ]; then
            P="$(kubectl -n "$NS" get deploy wazuh-dashboard -o jsonpath='{.spec.template.spec.containers[0].ports[0].containerPort}' 2>/dev/null || true)"
          fi
          test -n "${P:-}" || { echo "::error::Could not find dashboard port"; exit 1; }
          echo "port=$P" >> "$GITHUB_OUTPUT"

      - name: Optional port-forward to dashboard
        if: ${{ inputs.enable_port_forward == 'true' }}
        shell: bash
        env:
          PF_BIND: 127.0.0.1
          PF_PORT: ${{ inputs.local_forward_port }}
        run: |
          set -euo pipefail
          TARGET_PORT="${{ steps.dash.outputs.port }}"
          (pkill -f "port-forward .*:${PF_PORT}:" && sleep 1) || true
          nohup kubectl -n "$NS" port-forward --address "${PF_BIND}" deploy/wazuh-dashboard "${PF_PORT}:${TARGET_PORT}" > portforward.log 2>&1 &
          echo "::notice title=Browse Dashboard::http://localhost:${PF_PORT}"

      - name: Final status
        shell: bash
        run: |
          kubectl get sc -o wide
          kubectl -n "$NS" get pvc
          kubectl -n "$NS" get svc -o wide
          kubectl -n "$NS" get endpoints -o wide
          kubectl -n "$NS" get pods -o wide
