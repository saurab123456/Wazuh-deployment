name: Deploy Wazuh Agent (manual)

on:
  workflow_dispatch:

concurrency:
  group: deploy-wazuh-agent
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  deploy:
    runs-on:
      - self-hosted
      - linux
      - ronin
      - k8s
      - control-plane

    env:
      NS: wazuh
      IMAGE: ghcr.io/saurab123456/wazuh-agent:4.12.0
      AUTHD_PORT: "1515"   # manager authd
      EVENTS_PORT: "1514"  # remoted/events

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure kubectl is available (no sudo)
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$HOME/.local/bin"
          if ! command -v kubectl >/dev/null 2>&1; then
            curl -fsSL -o "$HOME/.local/bin/kubectl" "https://dl.k8s.io/release/$(curl -fsSL https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
            chmod +x "$HOME/.local/bin/kubectl"
          fi
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"
          kubectl version --client --output=yaml

      - name: Write kubeconfig from secret
        shell: bash
        env:
          KUBE_CONFIG_B64: ${{ secrets.KUBE_CONFIG_B64 }}
        run: |
          set -euo pipefail
          if [ -z "${KUBE_CONFIG_B64:-}" ]; then
            echo "::error::Missing repo secret KUBE_CONFIG_B64"; exit 1
          fi
          mkdir -p "$HOME/.kube"
          echo "$KUBE_CONFIG_B64" | base64 -d > "$HOME/.kube/config"
          chmod 600 "$HOME/.kube/config"
          echo "Context: $(kubectl config current-context || true)"
          kubectl get nodes -o wide || true
          kubectl get ns "$NS" >/dev/null 2>&1 || kubectl create ns "$NS"

      - name: Wait for manager (master) to be Ready
        shell: bash
        run: |
          set -euo pipefail
          for i in {1..120}; do
            MPOD="$(kubectl -n "$NS" get pod -l app=wazuh-manager,node-type=master -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)"
            if [ -n "$MPOD" ]; then
              kubectl -n "$NS" wait --for=condition=Ready "pod/$MPOD" --timeout=20s && break || true
            fi
            sleep 2
          done
          if [ -z "${MPOD:-}" ]; then
            echo "::error::No wazuh-manager master pod found in ns $NS"
            kubectl -n "$NS" get pods -l app=wazuh-manager || true
            exit 1
          fi
          echo "MASTER_POD=$MPOD" >> "$GITHUB_ENV"
          echo "Found master pod: $MPOD"
          WPOD="$(kubectl -n "$NS" get pod -l app=wazuh-manager,node-type=worker -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)"
          if [ -n "$WPOD" ]; then
            echo "WORKER_POD=$WPOD" >> "$GITHUB_ENV"
            echo "Found worker pod: $WPOD"
          fi

      # (Optional) If your GHCR image is private, create once and then uncomment imagePullSecrets below:
      # kubectl -n wazuh create secret docker-registry ghcr-secret \
      #   --docker-server=ghcr.io \
      #   --docker-username=YOUR_GITHUB_USERNAME \
      #   --docker-password=YOUR_GHCR_PAT

      - name: Confirm manager ports (no config patching)
        shell: bash
        run: |
          set -euo pipefail
          # Print last log lines; Wazuh defaults are authd:1515 and remoted:1514
          kubectl -n "$NS" logs "$MASTER_POD" --tail=400 || true

      - name: Apply Services, ConfigMap, and DaemonSet (send events to MASTER first)
        shell: bash
        run: |
          set -euo pipefail
          # NOTE: unquoted heredoc so ${IMAGE} etc. expand
          cat <<EOF | kubectl -n "$NS" apply -f -
          ---
          apiVersion: v1
          kind: Service
          metadata:
            name: wazuh
            labels: { app: wazuh-manager, node-type: master }
          spec:
            type: ClusterIP
            selector: { app: wazuh-manager, node-type: master }
            ports:
              - { name: authd, port: 1515, protocol: TCP, targetPort: 1515 }
          ---
          apiVersion: v1
          kind: Service
          metadata:
            name: wazuh-workers
            labels: { app: wazuh-manager, node-type: worker }
          spec:
            type: ClusterIP
            selector: { app: wazuh-manager, node-type: worker }
            ports:
              - { name: agents-events, port: 1514, protocol: TCP, targetPort: 1514 }
              - { name: authd,         port: 1515, protocol: TCP, targetPort: 1515 }
          ---
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: wazuh-agent-ossec
          data:
            ossec.conf: |
              <ossec_config>
                <client>
                  <server>
                    <address>wazuh.wazuh.svc.cluster.local</address>
                    <port>1514</port>
                    <protocol>tcp</protocol>
                  </server>
                </client>
                <localfile>
                  <location>/host/var/log/containers/*.log</location>
                  <log_format>syslog</log_format>
                  <only-future-events>yes</only-future-events>
                </localfile>
                <localfile>
                  <location>/host/var/log/pods/*/*/*.log</location>
                  <log_format>syslog</log_format>
                  <only-future-events>yes</only-future-events>
                </localfile>
                <localfile>
                  <location>/host/var/log/syslog</location>
                  <log_format>syslog</log_format>
                  <only-future-events>yes</only-future-events>
                </localfile>
              </ossec_config>
          ---
          apiVersion: apps/v1
          kind: DaemonSet
          metadata:
            name: wazuh-agent
            labels: { app: wazuh-agent }
          spec:
            selector: { matchLabels: { app: wazuh-agent } }
            updateStrategy: { type: RollingUpdate }
            template:
              metadata: { labels: { app: wazuh-agent } }
              spec:
                hostNetwork: true
                hostPID: true
                dnsPolicy: ClusterFirstWithHostNet
                terminationGracePeriodSeconds: 30
                tolerations:
                  - { key: node-role.kubernetes.io/master, operator: Exists, effect: NoSchedule }
                  - { key: node-role.kubernetes.io/control-plane, operator: Exists, effect: NoSchedule }
                # Uncomment if you created ghcr-secret for private images:
                # imagePullSecrets:
                #   - name: ghcr-secret
                containers:
                  - name: wazuh-agent
                    image: ${IMAGE}
                    imagePullPolicy: IfNotPresent
                    securityContext: { privileged: true, runAsUser: 0 }
                    env:
                      - name: NODE_NAME
                        valueFrom: { fieldRef: { fieldPath: spec.nodeName } }
                      - name: AUTHD_PORT
                        value: "${AUTHD_PORT}"
                      - name: MANAGER_DNS
                        value: "wazuh.wazuh.svc.cluster.local"   # enroll to MASTER
                      - name: GROUPS
                        value: "kubernetes"
                    command: ["/bin/sh","-c"]
                    args:
                      - |
                        set -e
                        AGENT_NAME="$NODE_NAME"
                        echo "Agent name: $AGENT_NAME"

                        mkdir -p /var/ossec/var/run /var/ossec/queue/sockets /var/ossec/queue/db
                        cp /config/ossec.conf /var/ossec/etc/ossec.conf
                        rm -f /var/ossec/var/run/*.pid /var/ossec/var/*.lock 2>/dev/null || true

                        enroll() {
                          echo "Enrolling to $MANAGER_DNS:$AUTHD_PORT (group=$GROUPS)…"
                          if [ -n "$GROUPS" ]; then
                            /var/ossec/bin/agent-auth -m "$MANAGER_DNS" -p "$AUTHD_PORT" -A "$AGENT_NAME" -G "$GROUPS"
                          else
                            /var/ossec/bin/agent-auth -m "$MANAGER_DNS" -p "$AUTHD_PORT" -A "$AGENT_NAME"
                          fi
                        }

                        # Retry enrollment up to 12 times (~2 minutes)
                        if [ ! -s /var/ossec/etc/client.keys ]; then
                          for i in $(seq 1 12); do
                            if enroll; then
                              break
                            fi
                            echo "Enroll attempt $i failed; retrying in 10s…"
                            sleep 10
                          done
                        fi

                        if [ ! -s /var/ossec/etc/client.keys ]; then
                          echo "ERROR: Enrollment failed; exiting."
                          exit 1
                        fi

                        echo "Starting Wazuh agent…"
                        /var/ossec/bin/wazuh-control start
                        sleep 5
                        /var/ossec/bin/wazuh-control status
                        tail -f /var/ossec/logs/ossec.log
                    readinessProbe:
                      exec:
                        command: ["/bin/sh","-c",'/var/ossec/bin/wazuh-control status | grep -q "is running"']
                      initialDelaySeconds: 30
                      periodSeconds: 10
                      failureThreshold: 6
                      timeoutSeconds: 5
                    livenessProbe:
                      exec:
                        command: ["/bin/sh","-c",'/var/ossec/bin/wazuh-control status | grep -q "is running"']
                      initialDelaySeconds: 60
                      periodSeconds: 30
                      failureThreshold: 3
                      timeoutSeconds: 5
                    lifecycle:
                      preStop:
                        exec:
                          command: ["/bin/sh","-c","/var/ossec/bin/wazuh-control stop || true"]
                    resources:
                      requests: { cpu: "100m", memory: "256Mi" }
                      limits:   { cpu: "1000m", memory: "1024Mi" }
                    volumeMounts:
                      - { name: ossec-conf-cm,   mountPath: /config,                    readOnly: true }
                      - { name: varlogcontainers, mountPath: /host/var/log/containers,   readOnly: true }
                      - { name: varlogpods,       mountPath: /host/var/log/pods,         readOnly: true }
                      - { name: varlog,           mountPath: /host/var/log,              readOnly: true }
                volumes:
                  - { name: ossec-conf-cm,   configMap: { name: wazuh-agent-ossec } }
                  - { name: varlogcontainers, hostPath: { path: /var/log/containers, type: DirectoryOrCreate } }
                  - { name: varlogpods,       hostPath: { path: /var/log/pods,       type: DirectoryOrCreate } }
                  - { name: varlog,           hostPath: { path: /var/log,            type: Directory } }
          EOF

          kubectl -n "$NS" rollout status ds/wazuh-agent --timeout=300s || true
          kubectl -n "$NS" get pods -l app=wazuh-agent -o wide || true

      - name: Verify enrollment on manager
        shell: bash
        run: |
          set -euo pipefail
          ok=0
          for i in {1..24}; do
            KEYS=$(kubectl -n "$NS" exec "$MASTER_POD" -- sh -lc 'wc -l /var/ossec/etc/client.keys | awk "{print \$1}"' || echo 0)
            COUNT=$(kubectl -n "$NS" exec "$MASTER_POD" -- sh -lc "/var/ossec/bin/agent_control -lc | grep -E '^[[:space:]]*ID:' | grep -v '(server)' | wc -l" || echo 0)
            echo "client.keys lines: $KEYS, agent_control count: $COUNT"
            if [ "${COUNT:-0}" -ge 1 ] || [ "${KEYS:-0}" -ge 5 ]; then ok=1; break; fi
            sleep 5
          done
          if [ "$ok" -ne 1 ]; then
            echo "::warning::Enrollment not visible yet; proceeding to auto-flip anyway."
          fi

      - name: Flip agent events to workers & restart DS
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "$NS" get cm wazuh-agent-ossec -o yaml \
          | sed 's#<address>wazuh\.wazuh\.svc\.cluster\.local</address>#<address>wazuh-workers.wazuh.svc.cluster.local</address>#' \
          | kubectl apply -f -
          kubectl -n "$NS" rollout restart ds/wazuh-agent
          kubectl -n "$NS" rollout status ds/wazuh-agent --timeout=300s || true

      - name: Verify worker remoted connections and Active agents
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${WORKER_POD:-}" ]; then
            WORKER_POD="$(kubectl -n "$NS" get pod -l app=wazuh-manager,node-type=worker -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)"
            [ -n "$WORKER_POD" ] && echo "WORKER_POD=$WORKER_POD" >> "$GITHUB_ENV"
          fi
          if [ -n "${WORKER_POD:-}" ]; then
            echo "=== Worker remoted recent ==="
            kubectl -n "$NS" logs "$WORKER_POD" --tail=300 \
              | egrep -i 'Listening on port 1514|Agent connected|Invalid ID|Authentication file changed' \
              | tail -n 120 || true
          else
            echo "::warning::No worker pod found; skipping worker log check."
          fi

          echo "=== agent_control -lc ==="
          kubectl -n "$NS" exec "$MASTER_POD" -- /var/ossec/bin/agent_control -lc || true

      - name: Final diagnostics
        shell: bash
        run: |
          set -euo pipefail
          echo "Pods:"
          kubectl -n "$NS" get pods -o wide || true
          echo
          echo "Services:"
          kubectl -n "$NS" get svc wazuh wazuh-workers -o wide || true
          echo
          echo "Manager ports (expect 1515 authd + 1514 remoted):"
          kubectl -n "$NS" logs "$MASTER_POD" --tail=300 \
            | egrep -i "Accepting connections on port 1515|Listening on port 1514/TCP" \
            | tail -n 80 || true
          echo
          echo "Agent connection logs:"
          for P in $(kubectl -n "$NS" get pods -l app=wazuh-agent -o name); do
            echo "=== $P ==="
            kubectl -n "$NS" logs "$P" --tail=300 \
              | egrep -i "Valid key|Reading authentication keys|Trying to connect|Connected to server|keep alive" \
              | tail -n 60 || true
          done
