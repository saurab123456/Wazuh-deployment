name: Deploy Wazuh (Official Kubernetes Manifests)

on:
  workflow_dispatch:
    inputs:
      overlay:
        description: "Overlay to deploy: single or production"
        required: true
        default: "single"
      wazuh_tag:
        description: "wazuh-kubernetes repo tag (e.g., v4.12.0)"
        required: true
        default: "v4.12.0"
      cleanup_unbound_pvcs:
        description: "Delete UNBOUND PVCs before deploy (true/false)"
        required: true
        default: "true"
      local_forward_port:
        description: "Local port for port-forward (optional)"
        required: true
        default: "8444"

jobs:
  deploy:
    runs-on: [self-hosted, linux, ronin, k8s, control-plane]
    timeout-minutes: 50

    env:
      NS: wazuh
      KUBECONFIG: ${{ github.workspace }}/kubeconfig.yaml
      WAZUH_K8S_TAG: ${{ inputs.wazuh_tag }}
      OVERLAY_CHOICE: ${{ inputs.overlay }}
      CLEANUP_UNBOUND_PVCS: ${{ inputs.cleanup_unbound_pvcs }}
      LOCAL_FORWARD_PORT: ${{ inputs.local_forward_port }}

    steps:
      - name: Checkout (this repo)
        uses: actions/checkout@v4

      - name: Ensure kubectl
        run: |
          set -e
          if ! command -v kubectl >/dev/null 2>&1; then
            KVER="$(curl -sS https://dl.k8s.io/release/stable.txt)"
            curl -sSLo kubectl "https://dl.k8s.io/release/${KVER}/bin/linux/amd64/kubectl"
            chmod +x kubectl && sudo mv kubectl /usr/local/bin/
          fi
          kubectl version --client=true | head -n 1

      - name: Write kubeconfig from secret
        env:
          KUBE_CONFIG_B64: ${{ secrets.KUBE_CONFIG_B64 }}
        run: |
          set -e
          test -n "$KUBE_CONFIG_B64" || { echo "::error::Secret KUBE_CONFIG_B64 missing"; exit 1; }
          echo "$KUBE_CONFIG_B64" | base64 -d > "$KUBECONFIG"
          kubectl cluster-info
          kubectl get nodes -o wide

      - name: Ensure namespace
        run: |
          kubectl create namespace "$NS" --dry-run=client -o yaml | kubectl apply -f -

      # ---------- SYSCTL: vm.max_map_count ----------
      - name: Apply sysctl DaemonSet (vm.max_map_count=262144 on all nodes)
        run: |
          cat > /tmp/wazuh-sysctl-ds.yaml <<'EOF'
          apiVersion: apps/v1
          kind: DaemonSet
          metadata:
            name: wazuh-sysctl
            namespace: kube-system
            labels:
              app: wazuh-sysctl
          spec:
            selector:
              matchLabels:
                app: wazuh-sysctl
            template:
              metadata:
                labels:
                  app: wazuh-sysctl
              spec:
                hostPID: true
                tolerations:
                  - operator: "Exists"
                containers:
                  - name: sysctl
                    image: busybox:1.36
                    securityContext:
                      privileged: true
                    command: ["/bin/sh","-c"]
                    args:
                      - |
                        set -e
                        echo 262144 > /host-proc/sys/vm/max_map_count
                        mkdir -p /host-etc/sysctl.d
                        echo "vm.max_map_count=262144" > /host-etc/sysctl.d/99-wazuh.conf
                        echo "vm.max_map_count now: $(cat /host-proc/sys/vm/max_map_count)"
                        sleep 60
                    volumeMounts:
                      - name: host-proc
                        mountPath: /host-proc
                      - name: host-etc
                        mountPath: /host-etc
                volumes:
                  - name: host-proc
                    hostPath:
                      path: /proc
                      type: Directory
                  - name: host-etc
                    hostPath:
                      path: /etc
                      type: Directory
          EOF
          kubectl apply -f /tmp/wazuh-sysctl-ds.yaml
          kubectl -n kube-system rollout status ds/wazuh-sysctl --timeout=180s || true
          kubectl -n kube-system delete ds/wazuh-sysctl --ignore-not-found=true
      # ---------- END SYSCTL ----------

      - name: Ensure dynamic StorageClass alias 'wazuh-storage'
        run: |
          set -e
          if kubectl get sc local-path >/dev/null 2>&1; then
            TARGET_SC="local-path"
          else
            TARGET_SC="$(kubectl get sc -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.provisioner}{"\n"}{end}' | awk '$2!="kubernetes.io/no-provisioner"{print $1; exit}')"
          fi
          test -n "$TARGET_SC" || { echo "::error::No dynamic StorageClass found"; exit 1; }
          TARGET_PROV="$(kubectl get sc "$TARGET_SC" -o jsonpath='{.provisioner}')"

          if kubectl get sc wazuh-storage >/dev/null 2>&1; then
            CUR_PROV="$(kubectl get sc wazuh-storage -o jsonpath='{.provisioner}')"
            if [ "$CUR_PROV" != "$TARGET_PROV" ]; then
              kubectl delete sc wazuh-storage
            fi
          fi

          cat <<EOF | kubectl apply -f -
          apiVersion: storage.k8s.io/v1
          kind: StorageClass
          metadata:
            name: wazuh-storage
          provisioner: ${TARGET_PROV}
          reclaimPolicy: Delete
          volumeBindingMode: WaitForFirstConsumer
          allowVolumeExpansion: true
          EOF

      - name: Fetch official wazuh-kubernetes repo
        run: |
          set -e
          rm -rf wazuh-kubernetes
          git clone --depth 1 --branch "$WAZUH_K8S_TAG" https://github.com/wazuh/wazuh-kubernetes.git
          ls -la wazuh-kubernetes | sed -n '1,120p'

      - name: Resolve overlay path (auto-detect)
        id: resolve
        run: |
          set -e
          WANT="${OVERLAY_CHOICE}"
          CANDIDATES="$(grep -RIl --include='*.yml' --include='*.yaml' -e 'wazuh-dashboard\|wazuh-manager\|wazuh-indexer' wazuh-kubernetes 2>/dev/null | xargs -r -n1 dirname | sort -u)"
          if [ -z "$CANDIDATES" ]; then
            echo "::error::No Wazuh manifests found in repo tag"
            exit 1
          fi
          PICK=""
          while IFS= read -r d; do
            dl="$(echo "$d" | tr '[:upper:]' '[:lower:]')"
            if [ "$WANT" = "single" ] && echo "$dl" | grep -q single; then PICK="$d"; break; fi
            if [ "$WANT" = "production" ] && echo "$dl" | grep -q prod; then PICK="$d"; break; fi
          done <<< "$CANDIDATES"
          if [ -z "$PICK" ]; then
            PICK="$(echo "$CANDIDATES" | head -n1)"
          fi
          echo "overlay_path=$PICK" >> "$GITHUB_OUTPUT"
          echo "Resolved overlay path: $PICK"

      - name: Optional cleanup: delete UNBOUND PVCs only
        run: |
          set -e
          if [ "${CLEANUP_UNBOUND_PVCS}" = "true" ]; then
            UNBOUND="$(kubectl -n "$NS" get pvc --no-headers 2>/dev/null | awk '$2!="Bound"{print $1}')"
            if [ -n "$UNBOUND" ]; then
              for pvc in $UNBOUND; do kubectl -n "$NS" delete pvc "$pvc" --ignore-not-found; done
            fi
          fi

      - name: Apply all manifests once (may fail on STS immutability)
        run: |
          set -e
          cd "${{ steps.resolve.outputs.overlay_path }}"
          kubectl apply -f .

      - name: Recreate StatefulSets cleanly (handle immutability)
        run: |
          set -e
          cd "${{ steps.resolve.outputs.overlay_path }}"
          STS_NAMES="$(kubectl get -f . -o name 2>/dev/null | grep '^statefulset' || true)"
          if [ -n "$STS_NAMES" ]; then
            echo "Deleting StatefulSets to avoid immutable-field conflicts..."
            # Namespace is embedded in files; delete by name in target namespace
            for n in $STS_NAMES; do
              # n looks like statefulset.apps/<name>
              NAME="$(echo "$n" | cut -d'/' -f2)"
              kubectl -n "$NS" delete statefulset "$NAME" --ignore-not-found=true
            done
            echo "Re-applying manifests..."
            kubectl apply -f .
          else
            echo "No StatefulSets detected in overlay."
          fi

      - name: Wait for core components
        run: |
          set -e
          kubectl -n "$NS" wait --for=condition=Ready pod -l app=wazuh-manager  --timeout=1200s || true
          kubectl -n "$NS" wait --for=condition=Ready pod -l app=wazuh-indexer  --timeout=1200s || true
          kubectl -n "$NS" wait --for=condition=Ready pod -l app=wazuh-dashboard --timeout=1200s || true
          kubectl -n "$NS" get pods -o wide

      - name: Expose Dashboard via fixed NodePort (svc/wazuh-dashboard-nodeport)
        run: |
          set -e
          DASH_SVC="wazuh-dashboard-nodeport"
          NODEPORT=30443
          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: Service
          metadata:
            name: ${DASH_SVC}
            namespace: ${NS}
          spec:
            type: NodePort
            selector:
              app: wazuh-dashboard
            ports:
            - name: https
              port: 443
              targetPort: 443
              protocol: TCP
              nodePort: ${NODEPORT}
          EOF
          NODE_IP="$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[0].address}' | head -n1)"
          echo "WAZUH_NODEPORT_URL=https://${NODE_IP}:${NODEPORT}"

      - name: Print port-forward one-liner (optional)
        run: |
          echo "If you prefer localhost instead of NodePort, run:"
          echo "  kubectl -n ${NS} port-forward svc/wazuh-dashboard-nodeport ${LOCAL_FORWARD_PORT}:443"
          echo "Then open: https://localhost:${LOCAL_FORWARD_PORT}  (accept the self-signed cert)"

      - name: Final status
        run: |
          kubectl -n "$NS" get svc -o wide
          kubectl -n "$NS" get pods -o wide
